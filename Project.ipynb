{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Set-Up Work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports are listed here.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the primary dataset and displays its head.\n",
    "primary_df = pd.read_csv(\"LeagueofLegends.csv\")\n",
    "primary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The initial shape of the dataframe, before any preprocessing is perofrmed, is shown here.\n",
    "print(primary_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes unnecessary columns from the primary dataset. The shape of the updated datatfame is shown afterwards to ensure columns were successfully dropped.\n",
    "primary_df.drop(['League', 'Season', 'Type', 'blueTeamTag', 'goldblueTop', 'goldblueJungle', 'goldblueMiddle', \n",
    "         'goldblueADC', 'goldblueSupport', 'redTop', 'goldredTop', 'redJungle', 'goldredJungle', \n",
    "         'redMiddle', 'goldredMiddle', 'redADC', 'goldredADC', 'redSupport', 'goldredSupport', 'redTeamTag', \n",
    "         'blueTop', 'blueMiddle', 'blueJungle', 'blueADC', 'blueSupport', 'golddiff', 'goldblue', 'bTowers', \n",
    "         'bInhibs', 'bDragons', 'bBarons','bHeralds', 'goldred', 'rTowers', 'rInhibs', 'rDragons', 'rBarons', \n",
    "         'rHeralds', 'blueBans', 'redBans', 'bKills', 'rKills'], axis=1, inplace=True)\n",
    "print(primary_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks for any null values in the primary dataset.\n",
    "primary_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provides basic descriptive statistics about the match length.\n",
    "primary_df.describe()['gamelength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a function to identify outliers after being provided a dataframe and a specific column name.\n",
    "def find_outliers(df, col):\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    IQR = q3-q1\n",
    "    outliers = df[((df[col] < (q1 - 1.5*IQR)) | (df[col] > (q3 + 1.5*IQR)))]\n",
    "    return outliers\n",
    "\n",
    "# Abnormally long or short matches are found and temporarily stored in a variable.\n",
    "gamelength_outliers = find_outliers(primary_df, 'gamelength').index\n",
    "workable_outliers = primary_df.loc[gamelength_outliers]\n",
    "print(gamelength_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes matches identified as outliers (based on game length) from the primary dataframe. The shape of the updated dataframe is shown afterwards to ensure removals have succeeded.\n",
    "primary_df = primary_df.drop(gamelength_outliers)\n",
    "print(primary_df.shape)\n",
    "primary_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_df = primary_df.sort_values(by = 'Address')\n",
    "primary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the kills dataset and displays its head.\n",
    "kills_df = pd.read_csv(\"kills.csv\")\n",
    "kills_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groups the kills dataset by address and team, and counts the number of kills said team has accumulatd in total.\n",
    "kills = kills_df.groupby([\"Address\", \"Team\"]).size().reset_index(name = \"Kills\")\n",
    "kills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separates the kills for each uniquue match by blue team's kills and red team's kills.\n",
    "bKills = kills[kills['Team'] == 'bKills']\n",
    "rKills = kills[kills['Team'] == 'rKills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a bKills column in the primary dataset that matches the each unique match.\n",
    "for row in bKills.index:\n",
    "    addr = bKills.loc[row, 'Address']\n",
    "    primary_df.loc[(primary_df['Address'] == addr), 'bKills'] = bKills.loc[row, 'Kills']\n",
    "\n",
    "print(primary_df[['Address', 'bKills']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a rKills column in the primary dataset that matches the each unique match.\n",
    "for row in rKills.index:\n",
    "    addr = rKills.loc[row, 'Address']\n",
    "    primary_df.loc[(primary_df['Address'] == addr), 'rKills'] = rKills.loc[row, 'Kills']\n",
    "    \n",
    "print(primary_df[['Address', 'bKills', 'rKills']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separates the deaths for each uniquue match by blue team's deaths and red team's deaths.\n",
    "primary_df['bDeaths'] = primary_df['rKills']\n",
    "primary_df['rDeaths'] = primary_df['bKills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the gold dataset and displays all of its columns.\n",
    "gold = pd.read_csv(\"gold.csv\")\n",
    "gold.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops all rows that are not of 'golddiff' type.\n",
    "for row in workable_outliers.index:\n",
    "    addr = workable_outliers.loc[row, 'Address']\n",
    "    gold = gold.drop(gold[gold['Address'] == addr].index)\n",
    "gold = gold.drop(gold[gold['Type'] != 'golddiff'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorts the gold dataframe by address for future merging.\n",
    "gold = gold.sort_values(by = 'Address')\n",
    "gold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines new columns in the primary dataframe using the gold dataframe's columns. \n",
    "primary_df['gd15min'] = gold['min_15']\n",
    "primary_df['gd30min'] = gold['min_30']\n",
    "primary_df['gd45min'] = gold['min_45']\n",
    "primary_df['gd56min'] = gold['min_56']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputes the row mean as the value for NaN values in each row.\n",
    "sel = primary_df[primary_df['gd56min'].isnull() & primary_df['gd45min'].notnull()].index\n",
    "primary_df.loc[sel, 'gd56min'] = primary_df.loc[sel, ['gd15min', 'gd30min', 'gd45min']].mean(axis=1)\n",
    "\n",
    "sel1 = primary_df[primary_df['gd45min'].isnull() & primary_df['gd30min'].notnull()].index\n",
    "primary_df.loc[sel1, 'gd45min'] = primary_df.loc[sel1, ['gd15min', 'gd30min']].mean(axis=1)\n",
    "primary_df.loc[sel1, 'gd56min'] = primary_df.loc[sel1, ['gd15min', 'gd30min']].mean(axis=1)\n",
    "\n",
    "sel2 = primary_df[primary_df['gd30min'].isnull()].index\n",
    "primary_df.loc[sel2, 'gd30min'] = primary_df.loc[sel2, 'gd15min']\n",
    "primary_df.loc[sel2, 'gd45min'] = primary_df.loc[sel2, 'gd15min']\n",
    "primary_df.loc[sel2, 'gd56min'] = primary_df.loc[sel2, 'gd15min']\n",
    "\n",
    "print(primary_df[['gd15min', 'gd30min', 'gd45min', 'gd56min']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Dataframes to Use Later, Created Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dataframe storing blue team compositions and their match results.\n",
    "blue_team_composition_df = primary_df.filter([\"Address\",\"blueTopChamp\",\"blueMiddleChamp\", \"blueADCChamp\", \"blueSupportChamp\", \"blueJungleChamp\", \"bResult\"])\n",
    "blue_team_composition_df = blue_team_composition_df[blue_team_composition_df[\"bResult\"] == 1]\n",
    "blue_team_composition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dataframe storing red team compositions and their match results.\n",
    "red_team_composition_df = primary_df.filter([\"Address\",\"redTopChamp\",\"redMiddleChamp\", \"redADCChamp\", \"redSupportChamp\", \"redJungleChamp\", \"rResult\"])\n",
    "red_team_composition_df = red_team_composition_df[red_team_composition_df[\"rResult\"] == 1]\n",
    "red_team_composition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the bans dataset and drops the 4th and 5th bans columns. The head is then displayed.\n",
    "bans_df = pd.read_csv(\"bans.csv\")\n",
    "bans_df.drop([\"ban_4\", \"ban_5\"], axis=1, inplace=True)\n",
    "bans_df = bans_df.dropna(how='any',axis=0)\n",
    "\n",
    "bans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dataframe out of blue team's bans for each unique match address.\n",
    "blue_team_bans_df = bans_df[bans_df[\"Team\"] == \"blueBans\"]\n",
    "blue_team_bans_df.drop(\"Team\", axis=1, inplace=True)\n",
    "blue_team_bans_df.rename(columns = {'ban_1':'b_ban1','ban_2':'b_ban2','ban_3':'b_ban3'}, inplace = True)\n",
    "\n",
    "bResult = primary_df[[\"Address\", \"bResult\"]]\n",
    "blue_team_bans_df = blue_team_bans_df.merge(bResult, on=\"Address\", how=\"left\")\n",
    "blue_team_bans_df = blue_team_bans_df[blue_team_bans_df[\"bResult\"] == 1]\n",
    "\n",
    "blue_team_bans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dataframe out of red team's bans for each unique match address.\n",
    "red_team_bans_df = bans_df[bans_df[\"Team\"] == \"redBans\"]\n",
    "red_team_bans_df.drop(\"Team\", axis=1, inplace=True)\n",
    "red_team_bans_df.rename(columns = {'ban_1':'r_ban1','ban_2':'r_ban2','ban_3':'r_ban3',}, inplace = True)\n",
    "\n",
    "rResult = primary_df[[\"Address\", \"rResult\"]]\n",
    "red_team_bans_df = red_team_bans_df.merge(rResult, on=\"Address\", how=\"left\")\n",
    "red_team_bans_df = red_team_bans_df[red_team_bans_df[\"rResult\"] == 1]\n",
    "\n",
    "red_team_bans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the monster objectives dataset and displays its head.\n",
    "monsters_df = pd.read_csv(\"monsters.csv\")\n",
    "monsters_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new dataframe to hold all of the ORIGINAL DRAGONS killed in all matches.\n",
    "original_dragons_df = monsters_df[monsters_df[\"Type\"] == \"DRAGON\"]\n",
    "\n",
    "# Creates a new dataframe to hold all of the FIRST ORIGINAL DRAGONS killed in each UNIQUE match.\n",
    "original_first_drags_df = original_dragons_df.sort_values(by=[\"Time\"]).groupby(\"Address\").first().reset_index()\n",
    "original_first_drags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new dataframe to hold all of the ELEMENTAL DRAGONS killed in all matches.\n",
    "elemental_dragons_df = monsters_df[monsters_df[\"Type\"].isin([\"AIR_DRAGON\", \"EARTH_DRAGON\", \"FIRE_DRAGON\", \"WATER_DRAGON\"])]\n",
    "\n",
    "# Creates a new dataframe to hold all of the FIRST ELEMENTAL DRAGONS killed in each UNIQUE match.\n",
    "elemental_first_drags_df = elemental_dragons_df.sort_values(by=[\"Time\"]).groupby(\"Address\").first().reset_index()\n",
    "elemental_first_drags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new dataframe to hold all of the ELDER DRAGONS killed in all matches.\n",
    "elder_dragons_df = monsters_df[monsters_df[\"Type\"] == \"ELDER_DRAGON\"]\n",
    "\n",
    "# Creates a new dataframe to hold all of the FIRST ELDER DRAGONS killed in each UNIQUE match.\n",
    "elder_first_drags_df = elder_dragons_df.sort_values(by=[\"Time\"]).groupby(\"Address\").first().reset_index()\n",
    "elder_first_drags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new dataframe to hold all of the RIFT HERALDS killed in all matches.\n",
    "rift_heralds_df = monsters_df[monsters_df[\"Type\"] == \"RIFT_HERALD\"]\n",
    "\n",
    "# Creates a new dataframe to hold all of the FIRST RIFT HERALDS killed in each UNIQUE match.\n",
    "first_rift_heralds_df = rift_heralds_df.sort_values(by=[\"Time\"]).groupby(\"Address\").first().reset_index()\n",
    "first_rift_heralds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new dataframe to hold all of the BARON NASHORS killed in all matches.\n",
    "baron_nashors_df = monsters_df[monsters_df[\"Type\"] == \"BARON_NASHOR\"]\n",
    "\n",
    "# Creates a new dataframe to hold all of the FIRST BARON NASHORS killed in each UNIQUE match.\n",
    "first_baron_nashors_df = baron_nashors_df.sort_values(by=[\"Time\"]).groupby(\"Address\").first().reset_index()\n",
    "first_baron_nashors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the structures dataset and displays its head.\n",
    "structures_df = pd.read_csv(\"structures.csv\")\n",
    "structures_df = structures_df.dropna()\n",
    "structures_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new dataframe to hold all of the OUTER TURRETS destroyed in all matches.\n",
    "outer_turrets_df = structures_df[structures_df[\"Type\"] == \"OUTER_TURRET\"]\n",
    "\n",
    "# Creates a new dataframe to hold all of the FIRST OUTER TURRETS destroyed in each UNIQUE match.\n",
    "first_outer_turrets_df = outer_turrets_df.sort_values(by=[\"Time\"]).groupby(\"Address\").first().reset_index()\n",
    "first_outer_turrets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates two new columns to hold the total objectives achieved for each team.\n",
    "primary_df['bTotal_Objectives'] = 0\n",
    "primary_df['rTotal_Objectives'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates workable dataframes that hold which teams acheived these objectives for each match.\n",
    "TObjectives = first_outer_turrets_df.groupby([\"Address\", \"Team\"]).size().reset_index(name = \"Towers\")\n",
    "ODObjectives = original_first_drags_df.groupby([\"Address\", \"Team\"]).size().reset_index(name = \"Dragons\")\n",
    "EDObjectives = elemental_first_drags_df.groupby([\"Address\", \"Team\"]).size().reset_index(name = \"Dragons\")\n",
    "ELObjectives = elder_first_drags_df.groupby([\"Address\", \"Team\"]).size().reset_index(name = \"Dragons\")\n",
    "HObjectives = first_rift_heralds_df.groupby([\"Address\", \"Team\"]).size().reset_index(name = \"Heralds\")\n",
    "BObjectives = first_baron_nashors_df.groupby([\"Address\", \"Team\"]).size().reset_index(name = \"Barons\")\n",
    "print(TObjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separates each dataframe into one for each team for each objective.\n",
    "bTObjectives = TObjectives[TObjectives['Team'] == 'bTowers']\n",
    "rTObjectives = TObjectives[TObjectives['Team'] == 'rTowers']\n",
    "bODObjectives = ODObjectives[ODObjectives['Team'] == 'bDragons']\n",
    "rODObjectives = ODObjectives[ODObjectives['Team'] == 'rDragons']\n",
    "bEDObjectives = EDObjectives[EDObjectives['Team'] == 'bDragons']\n",
    "rEDObjectives = EDObjectives[EDObjectives['Team'] == 'rDragons']\n",
    "bELObjectives = ELObjectives[ELObjectives['Team'] == 'bDragons']\n",
    "rELObjectives = ELObjectives[ELObjectives['Team'] == 'rDragons']\n",
    "bHObjectives = HObjectives[HObjectives['Team'] == 'bHeralds']\n",
    "rHObjectives = HObjectives[HObjectives['Team'] == 'rHeralds']\n",
    "bBObjectives = BObjectives[BObjectives['Team'] == 'bBarons']\n",
    "rBObjectives = BObjectives[BObjectives['Team'] == 'rBarons']\n",
    "print(bTObjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs the objective count for each blue team.\n",
    "for row in bTObjectives.index:\n",
    "    addr = bTObjectives.loc[row, 'Address']\n",
    "    primary_df.loc[(primary_df['Address'] == addr), 'bTotal_Objectives'] += bTObjectives.loc[row, 'Towers']\n",
    "for row in bODObjectives.index:\n",
    "    addr = bODObjectives.loc[row, 'Address']\n",
    "    primary_df.loc[(primary_df['Address'] == addr), 'bTotal_Objectives'] += bODObjectives.loc[row, 'Dragons']\n",
    "for row in bEDObjectives.index:\n",
    "    addr = bEDObjectives.loc[row, 'Address']\n",
    "    primary_df.loc[(primary_df['Address'] == addr), 'bTotal_Objectives'] += bEDObjectives.loc[row, 'Dragons']\n",
    "for row in bELObjectives.index:\n",
    "    addr = bELObjectives.loc[row, 'Address']\n",
    "    primary_df.loc[(primary_df['Address'] == addr), 'bTotal_Objectives'] += bELObjectives.loc[row, 'Dragons']\n",
    "for row in bHObjectives.index:\n",
    "    addr = bHObjectives.loc[row, 'Address']\n",
    "    primary_df.loc[(primary_df['Address'] == addr), 'bTotal_Objectives'] += bHObjectives.loc[row, 'Heralds']\n",
    "for row in bBObjectives.index:\n",
    "    addr = bBObjectives.loc[row, 'Address']\n",
    "    primary_df.loc[(primary_df['Address'] == addr), 'bTotal_Objectives'] += bBObjectives.loc[row, 'Barons']\n",
    "print(primary_df[['Address', 'bTotal_Objectives']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs the objective count for each red team.\n",
    "for row in rTObjectives.index:\n",
    "    addr = rTObjectives.loc[row, 'Address']\n",
    "    primary_df.loc[(primary_df['Address'] == addr), 'rTotal_Objectives'] += rTObjectives.loc[row, 'Towers']\n",
    "for row in rODObjectives.index:\n",
    "    addr = rODObjectives.loc[row, 'Address']\n",
    "    primary_df.loc[(primary_df['Address'] == addr), 'rTotal_Objectives'] += rODObjectives.loc[row, 'Dragons']\n",
    "for row in rEDObjectives.index:\n",
    "    addr = rEDObjectives.loc[row, 'Address']\n",
    "    primary_df.loc[(primary_df['Address'] == addr), 'rTotal_Objectives'] += rEDObjectives.loc[row, 'Dragons']\n",
    "for row in rELObjectives.index:\n",
    "    addr = rELObjectives.loc[row, 'Address']\n",
    "    primary_df.loc[(primary_df['Address'] == addr), 'rTotal_Objectives'] += rELObjectives.loc[row, 'Dragons']\n",
    "for row in rHObjectives.index:\n",
    "    addr = rHObjectives.loc[row, 'Address']\n",
    "    primary_df.loc[(primary_df['Address'] == addr), 'rTotal_Objectives'] += rHObjectives.loc[row, 'Heralds']\n",
    "for row in rBObjectives.index:\n",
    "    addr = rBObjectives.loc[row, 'Address']\n",
    "    primary_df.loc[(primary_df['Address'] == addr), 'rTotal_Objectives'] += rBObjectives.loc[row, 'Barons']\n",
    "print(primary_df[['Address', 'rTotal_Objectives']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to see the five number summary of each team.\n",
    "primary_df[['bTotal_Objectives', 'rTotal_Objectives']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranges the columns to be more readable.\n",
    "final_primary_df = primary_df.reindex(columns = ['Address', 'Year', 'bResult', 'rResult', 'gamelength', 'blueTopChamp', \n",
    "                                                 'blueJungleChamp', 'blueMiddleChamp', 'blueADCChamp', 'blueSupportChamp', 'redTopChamp', \n",
    "                                                 'redJungleChamp', 'redMiddleChamp', 'redADCChamp', 'redSupportChamp', 'bKills', \n",
    "                                                 'bDeaths', 'bTotal_Objectives', 'rKills',  'rDeaths', 'rTotal_Objectives', \n",
    "                                                 'gd15min', 'gd30min', 'gd45min', 'gd56min'])\n",
    "final_primary_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final state of the primary dataframe, after simple columns are added.\n",
    "final_primary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the cleaned values of game-length as a histogram.\n",
    "plt.figure('gamelength', figsize=(16,8))\n",
    "plt.title('Game Length')\n",
    "final_primary_df['gamelength'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = final_primary_df.boxplot(column=[\"gamelength\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the cleaned values of the years the matches take place as a histogram.\n",
    "plt.figure('Year', figsize=(16,8))\n",
    "plt.title('Year')\n",
    "final_primary_df['Year'].plot(kind='hist', bins=[2014,2015,2016,2017,2018,2019])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a scatter plot for the blue team's kills in relation to total kills.\n",
    "totalKills = final_primary_df['bKills'] + final_primary_df['rKills']\n",
    "plt.figure(figsize = (16,8))\n",
    "plt.scatter(\n",
    "    totalKills,\n",
    "    final_primary_df['bKills'],\n",
    "    c='black'\n",
    ")\n",
    "plt.xlabel('Total Kills')\n",
    "plt.ylabel('bKills')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a scatter plot for the red team's kills in relation to total kills.\n",
    "plt.figure(figsize = (16,8))\n",
    "plt.scatter(\n",
    "    totalKills,\n",
    "    final_primary_df['rKills'],\n",
    "    c='black'\n",
    ")\n",
    "plt.xlabel('Total Kills')\n",
    "plt.ylabel('rKills')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a correlation matrix for each metric.\n",
    "final_primary_df.corr().style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear vs Logistic Regression Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a Linear Regression model instance.\n",
    "LRModel = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the X and y values to fit the Linear Regression model for blue Kills and blue results.\n",
    "X = final_primary_df['bKills'].values.reshape(-1, 1)\n",
    "y = final_primary_df['bResult'].values.reshape(-1,1)\n",
    " \n",
    "LRModel.fit(X,y)\n",
    "print(\"Linear R-Squared of Blue Kills and Blue Results: \", LRModel.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing as above, but with a different metric.\n",
    "X = final_primary_df['bTotal_Objectives'].values.reshape(-1, 1)\n",
    "y = final_primary_df['bResult'].values.reshape(-1,1)\n",
    " \n",
    "LRModel.fit(X,y)\n",
    "print(\"Linear R-Squared of Blue Objectives and Blue Results: \", LRModel.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_primary_df['rKills'].values.reshape(-1, 1)\n",
    "y = final_primary_df['rResult'].values.reshape(-1,1)\n",
    "\n",
    "LRModel.fit(X,y)\n",
    "print(\"Linear R-Squared of Red Kills and Red Results: \", LRModel.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_primary_df['rTotal_Objectives'].values.reshape(-1, 1)\n",
    "y = final_primary_df['rResult'].values.reshape(-1,1)\n",
    "\n",
    "LRModel.fit(X,y)\n",
    "print(\"Linear R-Squared of Red Objectives and Red Results: \", LRModel.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the linear regression model to predict a blue win or a red loss based off of overall gold differential.\n",
    "X = final_primary_df[['gd15min', 'gd30min', 'gd45min']]\n",
    "y = final_primary_df['bResult']\n",
    " \n",
    "LRModel.fit(X, y)\n",
    "print(\"Linear R-Squared of Gold Differential and Blue Results: \", LRModel.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our final Linear Regression model to be used for our demo.\n",
    "X = final_primary_df[['bKills', 'bDeaths', 'bTotal_Objectives', 'gd15min', 'gd30min', 'gd45min']]\n",
    "y = final_primary_df['bResult']\n",
    "LRModel.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an instance of a Logistic Regression model.\n",
    "LogModel = LogisticRegression(max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above, but it is fitting the Logistic Regression model instead.\n",
    "X = final_primary_df['bKills'].values.reshape(-1, 1)\n",
    "y = final_primary_df['bResult'].values.reshape(-1,1)\n",
    "LogModel.fit(X,y.ravel())\n",
    "print(\"Logistic R-Squared of Blue Kills and Blue Results: \", LogModel.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_primary_df['bTotal_Objectives'].values.reshape(-1, 1)\n",
    "y = final_primary_df['bResult'].values.reshape(-1,1)\n",
    "LogModel.fit(X,y.ravel())\n",
    "print(\"Logistic R-Squared of Blue Objectives and Blue Results: \", LogModel.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_primary_df['rKills'].values.reshape(-1, 1)\n",
    "y = final_primary_df['rResult'].values.reshape(-1,1)\n",
    "LogModel.fit(X,y.ravel())\n",
    "print(\"Logistic R-Squared of Red Kills and Red Results: \", LogModel.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_primary_df['rTotal_Objectives'].values.reshape(-1, 1)\n",
    "y = final_primary_df['rResult'].values.reshape(-1,1)\n",
    "LogModel.fit(X,y.ravel())\n",
    "print(\"Logistic R-Squared of Red Objectives and Red Results: \", LogModel.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_primary_df[['gd15min', 'gd30min', 'gd45min']]\n",
    "y = final_primary_df['bResult']\n",
    "LogModel.fit(X, y)\n",
    "print(\"R-Squared of Gold Differential and Blue Results: \", LogModel.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our final Logistic Regression model to be used for our demo.\n",
    "X = final_primary_df[['bKills', 'bDeaths', 'bTotal_Objectives', 'gd15min', 'gd30min', 'gd45min']]\n",
    "y = final_primary_df['bResult']\n",
    "LogModel.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all of the R-Squared metrics of Logistic Regression is significantly greater than those of the Linear Regression, the Logistic Regression model will be more accurate and more efficient in predicting results with these metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori Algorithm (Team Compositions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabs the list of champions that appear across champion picks.\n",
    "champions_list = np.unique(final_primary_df[['blueTopChamp', 'blueJungleChamp','blueMiddleChamp','blueADCChamp','blueSupportChamp','redTopChamp', 'redJungleChamp','redMiddleChamp','redADCChamp','redSupportChamp']].values)\n",
    "champions_list = list(champions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabs all winning match addresses from the blue team compositions dataframe.\n",
    "match_addresses = blue_team_composition_df[\"Address\"]\n",
    "\n",
    "# Creates an empty dataframe with 'champions' as the items in blue team's team composition. 1's and 0's are filled as necessary if a champion was picked by said team during a match.\n",
    "blue_team_comp_basket = pd.DataFrame(0, index=range(len(match_addresses)), columns=champions_list)\n",
    "blue_team_comp_basket = blue_team_comp_basket.join(match_addresses)\n",
    "\n",
    "for index, row in blue_team_comp_basket.iterrows():\n",
    "    match_instance = blue_team_composition_df.iloc[[index]]\n",
    "    \n",
    "    blueTopChamp = match_instance[\"blueTopChamp\"].astype(\"string\").item()\n",
    "    blueJungleChamp = match_instance[\"blueJungleChamp\"].astype(\"string\").item()\n",
    "    blueMiddleChamp = match_instance[\"blueMiddleChamp\"].astype(\"string\").item()\n",
    "    blueADCChamp = match_instance[\"blueADCChamp\"].astype(\"string\").item()\n",
    "    blueSupportChamp = match_instance[\"blueSupportChamp\"].astype(\"string\").item()\n",
    "    \n",
    "    blue_team_comp_basket.iloc[[index], blue_team_comp_basket.columns.get_loc(blueTopChamp)] = 1\n",
    "    blue_team_comp_basket.iloc[[index], blue_team_comp_basket.columns.get_loc(blueJungleChamp)] = 1\n",
    "    blue_team_comp_basket.iloc[[index], blue_team_comp_basket.columns.get_loc(blueMiddleChamp)] = 1\n",
    "    blue_team_comp_basket.iloc[[index], blue_team_comp_basket.columns.get_loc(blueADCChamp)] = 1\n",
    "    blue_team_comp_basket.iloc[[index], blue_team_comp_basket.columns.get_loc(blueSupportChamp)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs the apriori algorithm on blue team's team compositions and returns support/confidence values for common picks.\n",
    "blue_team_comp_basket.reset_index(drop=True, inplace=True)\n",
    "fixed_blue_team_comp_basket = blue_team_comp_basket.set_index(\"Address\")\n",
    "\n",
    "frequent_items = apriori(fixed_blue_team_comp_basket, min_support=0.011, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"lift\", min_threshold = 1)\n",
    "\n",
    "rules = rules.sort_values([\"confidence\", \"lift\"], ascending=[False,False])\n",
    "rules.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabs all winning match addresses from the red team compositions dataframe.\n",
    "match_addresses = red_team_composition_df[\"Address\"]\n",
    "\n",
    "# Creates an empty dataframe with 'champions' as the items in red team's team composition. 1's and 0's are filled as necessary if a champion was picked by said team during a match.\n",
    "red_team_comp_basket = pd.DataFrame(0, index=range(len(match_addresses)), columns=champions_list)\n",
    "red_team_comp_basket = red_team_comp_basket.join(match_addresses)\n",
    "\n",
    "for index, row in red_team_comp_basket.iterrows():\n",
    "    match_instance = red_team_composition_df.iloc[[index]]\n",
    "    \n",
    "    redTopChamp = match_instance[\"redTopChamp\"].astype(\"string\").item()\n",
    "    redJungleChamp = match_instance[\"redJungleChamp\"].astype(\"string\").item()\n",
    "    redMiddleChamp = match_instance[\"redMiddleChamp\"].astype(\"string\").item()\n",
    "    redADCChamp = match_instance[\"redADCChamp\"].astype(\"string\").item()\n",
    "    redSupportChamp = match_instance[\"redSupportChamp\"].astype(\"string\").item()\n",
    "    \n",
    "    red_team_comp_basket.iloc[[index], red_team_comp_basket.columns.get_loc(redTopChamp)] = 1\n",
    "    red_team_comp_basket.iloc[[index], red_team_comp_basket.columns.get_loc(redJungleChamp)] = 1\n",
    "    red_team_comp_basket.iloc[[index], red_team_comp_basket.columns.get_loc(redMiddleChamp)] = 1\n",
    "    red_team_comp_basket.iloc[[index], red_team_comp_basket.columns.get_loc(redADCChamp)] = 1\n",
    "    red_team_comp_basket.iloc[[index], red_team_comp_basket.columns.get_loc(redSupportChamp)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs the apriori algorithm on red team's team compositions and returns support/confidence values for common picks.\n",
    "red_team_comp_basket.reset_index(drop=True, inplace=True)\n",
    "fixed_red_team_comp_basket = red_team_comp_basket.set_index(\"Address\")\n",
    "frequent_items = apriori(fixed_red_team_comp_basket, min_support=0.011, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"lift\", min_threshold = 1)\n",
    "rules = rules.sort_values([\"confidence\", \"lift\"], ascending=[False,False])\n",
    "rules.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori Algorithm (Team Bans):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabs the list of champions that appear across champion bans.\n",
    "banned_champions_list = np.unique(bans_df[['ban_1', 'ban_2','ban_3']].values)\n",
    "banned_champions_list = list(champions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabs all match addresses from the blue bans dataframe.\n",
    "match_addresses_b = blue_team_bans_df[\"Address\"]\n",
    "\n",
    "# Creates an empty dataframe with 'champions' as the items in blue team's bans. 1's and 0's are filled as necessary if a champion was banned by said team during a match.\n",
    "blue_team_bans_basket = pd.DataFrame(0, index=range(len(match_addresses_b)), columns=champions_list)\n",
    "blue_team_bans_basket = blue_team_bans_basket.join(match_addresses_b)\n",
    "\n",
    "for index, row in blue_team_bans_basket.iterrows():\n",
    "    match_instance = blue_team_bans_df.iloc[[index]]\n",
    "    \n",
    "    b_ban1 = match_instance[\"b_ban1\"].astype(\"string\").item()\n",
    "    b_ban2 = match_instance[\"b_ban2\"].astype(\"string\").item()\n",
    "    b_ban3 = match_instance[\"b_ban3\"].astype(\"string\").item()\n",
    "    \n",
    "    blue_team_bans_basket.iloc[[index], blue_team_bans_basket.columns.get_loc(b_ban1)] = 1\n",
    "    blue_team_bans_basket.iloc[[index], blue_team_bans_basket.columns.get_loc(b_ban2)] = 1\n",
    "    blue_team_bans_basket.iloc[[index], blue_team_bans_basket.columns.get_loc(b_ban3)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs the apriori algorithm on blue team's bans and returns support/confidence values for common bans.\n",
    "blue_team_bans_basket.reset_index(drop=True, inplace=True)\n",
    "fixed_blue_team_bans_basket = blue_team_bans_basket.set_index(\"Address\")\n",
    "frequent_items = apriori(fixed_blue_team_bans_basket, min_support=0.011, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"lift\", min_threshold = 1)\n",
    "rules = rules.sort_values([\"confidence\", \"lift\"], ascending=[False,False])\n",
    "rules.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabs all match addresses from the blue bans dataframe.\n",
    "match_addresses_r = red_team_bans_df[\"Address\"]\n",
    "\n",
    "# Creates an empty dataframe with 'champions' as the items in blue team's team composition. 1's and 0's are filled as necessary if a champion was banned by said team during a match.\n",
    "red_team_bans_basket = pd.DataFrame(0, index=range(len(match_addresses_r)), columns=champions_list)\n",
    "red_team_bans_basket = red_team_bans_basket.join(match_addresses_r)\n",
    "\n",
    "for index, row in red_team_bans_basket.iterrows():\n",
    "    match_instance = red_team_bans_df.iloc[[index]]\n",
    "    \n",
    "    r_ban1 = match_instance[\"r_ban1\"].astype(\"string\").item()\n",
    "    r_ban2 = match_instance[\"r_ban2\"].astype(\"string\").item()\n",
    "    r_ban3 = match_instance[\"r_ban3\"].astype(\"string\").item()\n",
    "    \n",
    "    red_team_bans_basket.iloc[[index], red_team_bans_basket.columns.get_loc(r_ban1)] = 1\n",
    "    red_team_bans_basket.iloc[[index], red_team_bans_basket.columns.get_loc(r_ban2)] = 1\n",
    "    red_team_bans_basket.iloc[[index], red_team_bans_basket.columns.get_loc(r_ban3)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs the apriori algorithm on red team's bans and returns support/confidence values for common bans.\n",
    "red_team_bans_basket.reset_index(drop=True, inplace=True)\n",
    "fixed_red_team_bans_basket = red_team_bans_basket.set_index(\"Address\")\n",
    "frequent_items = apriori(fixed_red_team_bans_basket, min_support=0.03, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"lift\", min_threshold = 1)\n",
    "rules = rules.sort_values([\"confidence\", \"lift\"], ascending=[False,False])\n",
    "rules.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the X and Y's from earlier, we will test our Linear Regression model and print the accuracy.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.25)\n",
    "pred = LRModel.predict(xtest)\n",
    "print(\"Mean squared error: \", np.mean((pred - ytest) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the X and Y's from earlier, we will test our Logistic Regression model and print the accuracy.\n",
    "pred = LogModel.predict(xtest)\n",
    "print(\"Accuracy\", metrics.accuracy_score(ytest, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apriori Demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row = {\"Address\": \"http://matchhistory.na.leagueoflegends.com/en/#match-details/samplehash\",\n",
    "              \"redTopChamp\": \"Volibear\",\n",
    "              \"redJungleChamp\": \"Rengar\",\n",
    "              \"redMiddleChamp\": \"Veigar\",\n",
    "              \"redADCChamp\": \"Xayah\",\n",
    "              \"redSupportChamp\": \"Rakan\"}\n",
    "\n",
    "for i in range(100):\n",
    "    red_test_composition_df = red_team_composition_df.append(sample_row, ignore_index = True)\n",
    "\n",
    "# Grabs all winning match addresses from the red team compositions dataframe.\n",
    "match_addresses = red_test_composition_df[\"Address\"]\n",
    "\n",
    "# Creates an empty dataframe with 'champions' as the items in red team's team composition. 1's and 0's are filled as necessary if a champion was picked by said team during a match.\n",
    "red_test_comp_basket = pd.DataFrame(0, index=range(len(match_addresses)), columns=champions_list)\n",
    "red_test_comp_basket = red_test_comp_basket.join(match_addresses)\n",
    "\n",
    "for index, row in red_test_comp_basket.iterrows():\n",
    "    match_instance = red_test_composition_df.iloc[[index]]\n",
    "    \n",
    "    redTopChamp = match_instance[\"redTopChamp\"].astype(\"string\").item()\n",
    "    redJungleChamp = match_instance[\"redJungleChamp\"].astype(\"string\").item()\n",
    "    redMiddleChamp = match_instance[\"redMiddleChamp\"].astype(\"string\").item()\n",
    "    redADCChamp = match_instance[\"redADCChamp\"].astype(\"string\").item()\n",
    "    redSupportChamp = match_instance[\"redSupportChamp\"].astype(\"string\").item()\n",
    "    \n",
    "    red_test_comp_basket.iloc[[index], red_test_comp_basket.columns.get_loc(redTopChamp)] = 1\n",
    "    red_test_comp_basket.iloc[[index], red_test_comp_basket.columns.get_loc(redJungleChamp)] = 1\n",
    "    red_test_comp_basket.iloc[[index], red_test_comp_basket.columns.get_loc(redMiddleChamp)] = 1\n",
    "    red_test_comp_basket.iloc[[index], red_test_comp_basket.columns.get_loc(redADCChamp)] = 1\n",
    "    red_test_comp_basket.iloc[[index], red_test_comp_basket.columns.get_loc(redSupportChamp)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs the apriori algorithm on red team's team compositions and returns support/confidence values for common picks.\n",
    "red_test_comp_basket.reset_index(drop=True, inplace=True)\n",
    "fixed_red_test_comp_basket = red_test_comp_basket.set_index(\"Address\")\n",
    "frequent_items = apriori(fixed_red_test_comp_basket, min_support=0.011, use_colnames=True)\n",
    "rules = association_rules(frequent_items, metric=\"lift\", min_threshold = 1)\n",
    "rules = rules.sort_values([\"confidence\", \"lift\"], ascending=[False,False])\n",
    "rules.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd2c9a4755191081f04923b934e9adf016dbf982a160ac466e519d69b6b5ec0a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
